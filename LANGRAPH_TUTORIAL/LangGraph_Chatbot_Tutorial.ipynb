{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42dbcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LangGraph Chatbot\n",
    "=============================================================================\n",
    "\n",
    "A comprehensive implementation of a conversational AI chatbot using LangGraph\n",
    "with proper organization, error handling, and testing capabilities.\n",
    "\n",
    "Author: Niyantarana Tagore\n",
    "Date: 2025-06-29\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e93525df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph-checkpoint-sqlite in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (2.0.10)\n",
      "Requirement already satisfied: aiosqlite>=0.20 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.21.0)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.21 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (2.0.26)\n",
      "Requirement already satisfied: sqlite-vec>=0.1.6 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.1.6)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from aiosqlite>=0.20->langgraph-checkpoint-sqlite) (4.13.2)\n",
      "Requirement already satisfied: langchain-core>=0.2.38 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.3.66)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.10.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.4.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2.11.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/niyantarana/miniconda3/envs/bia_genai/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langgraph langsmith langchain-openai python-dotenv\n",
    "!pip install -q matplotlib graphviz\n",
    "!pip install langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "try:\n",
    "    from langgraph.graph import StateGraph, START, END\n",
    "    from langgraph.graph.message import add_messages\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    "    from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "    from langchain_openai import ChatOpenAI\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Required packages not installed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Constants\n",
    "@dataclass\n",
    "class ChatbotConfig:\n",
    "    \"\"\"Configuration settings for the chatbot.\"\"\"\n",
    "    model_name: str = \"gpt-4o-mini\"\n",
    "    temperature: float = 0.7\n",
    "    max_retries: int = 3\n",
    "    timeout: int = 30\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationState(TypedDict):\n",
    "    \"\"\"Type definition for conversation state.\"\"\"\n",
    "    messages: List[BaseMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "def setup_logging(level: int = logging.INFO) -> logging.Logger:\n",
    "    \"\"\"Configure logging for the application.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "# Initialize logger\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvironmentManager:\n",
    "    \"\"\"Manages environment setup and API key configuration.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup_openai_key() -> bool:\n",
    "        \"\"\"Setup OpenAI API key.\"\"\"\n",
    "        try:\n",
    "            if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "                import getpass\n",
    "                openai_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "                if not openai_key.strip():\n",
    "                    logger.warning(\"No OpenAI API key provided\")\n",
    "                    return False\n",
    "                os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "            logger.info(\"âœ… OpenAI API key configured\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to setup OpenAI key: {e}\")\n",
    "            return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup_langsmith_key() -> bool:\n",
    "        \"\"\"Setup LangSmith API key (optional).\"\"\"\n",
    "        try:\n",
    "            if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "                import getpass\n",
    "                print(\"LangSmith setup (optional but recommended for debugging):\")\n",
    "                langsmith_key = getpass.getpass(\n",
    "                    \"Enter your LangSmith API Key (or press Enter to skip): \"\n",
    "                )\n",
    "                \n",
    "                if langsmith_key.strip():\n",
    "                    os.environ[\"LANGSMITH_API_KEY\"] = langsmith_key\n",
    "                    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "                    os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph-Tutorial\"\n",
    "                    logger.info(\"âœ… LangSmith tracing enabled\")\n",
    "                    return True\n",
    "                else:\n",
    "                    logger.info(\"âš ï¸ Skipping LangSmith setup\")\n",
    "                    return False\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to setup LangSmith: {e}\")\n",
    "            return False\n",
    "    \n",
    "    @classmethod\n",
    "    def setup_environment(cls) -> bool:\n",
    "        \"\"\"Setup complete environment.\"\"\"\n",
    "        try:\n",
    "            openai_success = cls.setup_openai_key()\n",
    "            cls.setup_langsmith_key()  # Optional, don't fail if it doesn't work\n",
    "            \n",
    "            if openai_success:\n",
    "                logger.info(\"ðŸš€ Environment setup complete\")\n",
    "                return True\n",
    "            else:\n",
    "                logger.error(\"âŒ Environment setup failed - OpenAI key required\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Environment setup failed: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMManager:\n",
    "    \"\"\"Manages the Language Model instance and operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ChatbotConfig):\n",
    "        self.config = config\n",
    "        self._llm = None\n",
    "    \n",
    "    @property\n",
    "    def llm(self) -> ChatOpenAI:\n",
    "        \"\"\"Lazy initialization of the LLM.\"\"\"\n",
    "        if self._llm is None:\n",
    "            self._llm = self._create_llm()\n",
    "        return self._llm\n",
    "    \n",
    "    def _create_llm(self) -> ChatOpenAI:\n",
    "        \"\"\"Create and configure the language model.\"\"\"\n",
    "        try:\n",
    "            llm = ChatOpenAI(\n",
    "                model=self.config.model_name,\n",
    "                temperature=self.config.temperature,\n",
    "                max_retries=self.config.max_retries,\n",
    "                request_timeout=self.config.timeout,\n",
    "            )\n",
    "            logger.info(f\"âœ… Language model initialized: {self.config.model_name}\")\n",
    "            return llm\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize LLM: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def test_connection(self) -> bool:\n",
    "        \"\"\"Test the LLM connection.\"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(\"Say hello in a friendly way!\")\n",
    "            logger.info(f\"âœ… LLM test successful: {response.content[:50]}...\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM test failed: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotNode:\n",
    "    \"\"\"Encapsulates the chatbot node functionality.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_manager: LLMManager):\n",
    "        self.llm_manager = llm_manager\n",
    "    \n",
    "    def process(self, state: ConversationState) -> Dict[str, List[BaseMessage]]:\n",
    "        \"\"\"\n",
    "        Process the conversation state and generate a response.\n",
    "        \n",
    "        Args:\n",
    "            state: Current conversation state containing message history\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing new messages to add to state\n",
    "            \n",
    "        Raises:\n",
    "            Exception: If LLM processing fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            messages = state[\"messages\"]\n",
    "            if not messages:\n",
    "                raise ValueError(\"No messages in state\")\n",
    "            \n",
    "            response = self.llm_manager.llm.invoke(messages)\n",
    "            \n",
    "            if not response or not response.content:\n",
    "                raise ValueError(\"Empty response from LLM\")\n",
    "            \n",
    "            return {\"messages\": [response]}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Chatbot node processing failed: {e}\")\n",
    "            # Return an error message instead of crashing\n",
    "            error_response = AIMessage(\n",
    "                content=\"I apologize, but I encountered an error processing your request. Please try again.\"\n",
    "            )\n",
    "            return {\"messages\": [error_response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    \"\"\"Manages conversation threads and memory.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memory = MemorySaver()\n",
    "        self._active_threads: Dict[str, Any] = {}\n",
    "    \n",
    "    def create_thread_id(self) -> str:\n",
    "        \"\"\"Generate a unique thread ID.\"\"\"\n",
    "        return str(uuid.uuid4())\n",
    "    \n",
    "    def get_config(self, thread_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get configuration for a conversation thread.\"\"\"\n",
    "        return {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    def list_active_threads(self) -> List[str]:\n",
    "        \"\"\"List all active conversation threads.\"\"\"\n",
    "        return list(self._active_threads.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e7c006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangGraphChatbot:\n",
    "    \"\"\"Main chatbot class that orchestrates all components.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Optional[ChatbotConfig] = None):\n",
    "        self.config = config or ChatbotConfig()\n",
    "        self.llm_manager = LLMManager(self.config)\n",
    "        self.conversation_manager = ConversationManager()\n",
    "        self.chatbot_node = ChatbotNode(self.llm_manager)\n",
    "        \n",
    "        # Build graphs\n",
    "        self._simple_graph = None\n",
    "        self._memory_graph = None\n",
    "    \n",
    "    def _build_simple_graph(self):\n",
    "        \"\"\"Build the simple chatbot graph without memory.\"\"\"\n",
    "        try:\n",
    "            graph_builder = StateGraph(ConversationState)\n",
    "            graph_builder.add_node(\"chatbot\", self.chatbot_node.process)\n",
    "            graph_builder.add_edge(START, \"chatbot\")\n",
    "            graph_builder.add_edge(\"chatbot\", END)\n",
    "            \n",
    "            self._simple_graph = graph_builder.compile()\n",
    "            logger.info(\"âœ… Simple chatbot graph created\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to build simple graph: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _build_memory_graph(self):\n",
    "        \"\"\"Build the chatbot graph with memory.\"\"\"\n",
    "        try:\n",
    "            graph_builder = StateGraph(ConversationState)\n",
    "            graph_builder.add_node(\"chatbot\", self.chatbot_node.process)\n",
    "            graph_builder.add_edge(START, \"chatbot\")\n",
    "            graph_builder.add_edge(\"chatbot\", END)\n",
    "            \n",
    "            self._memory_graph = graph_builder.compile(\n",
    "                checkpointer=self.conversation_manager.memory\n",
    "            )\n",
    "            logger.info(\"âœ… Memory-enabled chatbot graph created\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to build memory graph: {e}\")\n",
    "            raise\n",
    "    \n",
    "    @property\n",
    "    def simple_graph(self):\n",
    "        \"\"\"Get the simple graph (lazy initialization).\"\"\"\n",
    "        if self._simple_graph is None:\n",
    "            self._build_simple_graph()\n",
    "        return self._simple_graph\n",
    "    \n",
    "    @property\n",
    "    def memory_graph(self):\n",
    "        \"\"\"Get the memory-enabled graph (lazy initialization).\"\"\"\n",
    "        if self._memory_graph is None:\n",
    "            self._build_memory_graph()\n",
    "        return self._memory_graph\n",
    "    \n",
    "    def chat_simple(self, user_input: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Simple chat without memory.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's message\n",
    "            \n",
    "        Returns:\n",
    "            Conversation result\n",
    "        \"\"\"\n",
    "        try:\n",
    "            initial_state = {\n",
    "                \"messages\": [HumanMessage(content=user_input)]\n",
    "            }\n",
    "            return self.simple_graph.invoke(initial_state)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Simple chat failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def chat_with_memory(self, user_input: str, thread_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Chat with memory persistence.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's message\n",
    "            thread_id: Optional thread ID (creates new if None)\n",
    "            \n",
    "        Returns:\n",
    "            Conversation result\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if thread_id is None:\n",
    "                thread_id = self.conversation_manager.create_thread_id()\n",
    "            \n",
    "            config = self.conversation_manager.get_config(thread_id)\n",
    "            \n",
    "            result = self.memory_graph.invoke(\n",
    "                {\"messages\": [HumanMessage(content=user_input)]},\n",
    "                config\n",
    "            )\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Memory chat failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def initialize(self) -> bool:\n",
    "        \"\"\"Initialize the chatbot system.\"\"\"\n",
    "        try:\n",
    "            # Setup environment\n",
    "            if not EnvironmentManager.setup_environment():\n",
    "                return False\n",
    "            \n",
    "            # Test LLM connection\n",
    "            if not self.llm_manager.test_connection():\n",
    "                return False\n",
    "            \n",
    "            # Build graphs (lazy initialization will happen on first use)\n",
    "            logger.info(\"ðŸŽ‰ Chatbot system initialized successfully\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Initialization failed: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0177ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotTester:\n",
    "    \"\"\"Testing utilities for the chatbot system.\"\"\"\n",
    "    \n",
    "    def __init__(self, chatbot: LangGraphChatbot):\n",
    "        self.chatbot = chatbot\n",
    "    \n",
    "    def print_conversation(self, result: Dict[str, Any], title: str = \"\"):\n",
    "        \"\"\"Pretty print conversation results.\"\"\"\n",
    "        if title:\n",
    "            print(f\"\\nðŸ¤– {title}\")\n",
    "            print(\"=\" * (len(title) + 4))\n",
    "        \n",
    "        messages = result.get(\"messages\", [])\n",
    "        for message in messages:\n",
    "            if isinstance(message, HumanMessage):\n",
    "                print(f\"ðŸ‘¤ Human: {message.content}\")\n",
    "            elif isinstance(message, AIMessage):\n",
    "                print(f\"ðŸ¤– AI: {message.content}\")\n",
    "        print()\n",
    "    \n",
    "    def test_simple_chatbot(self, test_cases: List[str]):\n",
    "        \"\"\"Test simple chatbot functionality.\"\"\"\n",
    "        print(\"ðŸ§ª Testing Simple Chatbot\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        for i, test_case in enumerate(test_cases, 1):\n",
    "            try:\n",
    "                result = self.chatbot.chat_simple(test_case)\n",
    "                self.print_conversation(result, f\"Test Case {i}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Test case {i} failed: {e}\")\n",
    "    \n",
    "    def test_memory_functionality(self, thread_id: str = \"test_conversation\"):\n",
    "        \"\"\"Test memory functionality.\"\"\"\n",
    "        print(\"ðŸ§  Testing Memory Functionality\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        test_sequence = [\n",
    "            \"Hi! My name is Niyantarana Tagore and I am an AI Agent Developer.\",\n",
    "            \"What's my name and what do I do?\",\n",
    "            \"What programming languages should I learn for AI development?\"\n",
    "        ]\n",
    "        \n",
    "        for i, user_input in enumerate(test_sequence, 1):\n",
    "            try:\n",
    "                result = self.chatbot.chat_with_memory(user_input, thread_id)\n",
    "                self.print_conversation(result, f\"Memory Test {i}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Memory test {i} failed: {e}\")\n",
    "    \n",
    "    def test_thread_isolation(self):\n",
    "        \"\"\"Test that different threads maintain separate conversations.\"\"\"\n",
    "        print(\"ðŸ”„ Testing Thread Isolation\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # First conversation\n",
    "        result1 = self.chatbot.chat_with_memory(\n",
    "            \"My favorite color is blue\", \n",
    "            \"thread_1\"\n",
    "        )\n",
    "        self.print_conversation(result1, \"Thread 1 - Setup\")\n",
    "        \n",
    "        # Second conversation\n",
    "        result2 = self.chatbot.chat_with_memory(\n",
    "            \"My favorite color is red\", \n",
    "            \"thread_2\"\n",
    "        )\n",
    "        self.print_conversation(result2, \"Thread 2 - Setup\")\n",
    "        \n",
    "        # Test memory isolation\n",
    "        result3 = self.chatbot.chat_with_memory(\n",
    "            \"What's my favorite color?\", \n",
    "            \"thread_1\"\n",
    "        )\n",
    "        self.print_conversation(result3, \"Thread 1 - Recall\")\n",
    "        \n",
    "        result4 = self.chatbot.chat_with_memory(\n",
    "            \"What's my favorite color?\", \n",
    "            \"thread_2\"\n",
    "        )\n",
    "        self.print_conversation(result4, \"Thread 2 - Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6ebbe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 10:53:30,589 - __main__ - WARNING - No OpenAI API key provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith setup (optional but recommended for debugging):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 10:53:32,054 - __main__ - INFO - âš ï¸ Skipping LangSmith setup\n",
      "2025-06-29 10:53:32,055 - __main__ - ERROR - âŒ Environment setup failed - OpenAI key required\n",
      "2025-06-29 10:53:32,066 - __main__ - ERROR - Failed to initialize chatbot system\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function demonstrating the chatbot usage.\"\"\"\n",
    "    # Initialize chatbot\n",
    "    config = ChatbotConfig(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    chatbot = LangGraphChatbot(config)\n",
    "    \n",
    "    # Initialize system\n",
    "    if not chatbot.initialize():\n",
    "        logger.error(\"Failed to initialize chatbot system\")\n",
    "        return\n",
    "    \n",
    "    # Run tests\n",
    "    tester = ChatbotTester(chatbot)\n",
    "    \n",
    "    # Test simple functionality\n",
    "    simple_test_cases = [\n",
    "        \"Hello! What's your name?\",\n",
    "        \"What is the GATE cutoff for ECE?\",\n",
    "        \"What are the subjects in GATE ECE?\"\n",
    "    ]\n",
    "    tester.test_simple_chatbot(simple_test_cases)\n",
    "    \n",
    "    # Test memory functionality\n",
    "    tester.test_memory_functionality()\n",
    "    \n",
    "    # Test thread isolation\n",
    "    tester.test_thread_isolation()\n",
    "    \n",
    "    print(\"âœ… All tests completed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– LangGraph Chatbot System\n",
      "========================================\n",
      "ðŸš€ Setting up environment...\n",
      "\n",
      "ðŸ”‘ OpenAI API Key Setup\n",
      "Get your API key from: https://platform.openai.com/api-keys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 10:53:33,768 - __main__ - WARNING - âŒ No OpenAI API key provided\n",
      "2025-06-29 10:53:33,769 - __main__ - ERROR - âŒ Environment setup failed - OpenAI key required\n",
      "2025-06-29 10:53:33,776 - __main__ - ERROR - Failed to initialize chatbot system\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: You can also set the OPENAI_API_KEY environment variable\n",
      "\n",
      "ðŸ’¡ Solutions:\n",
      "1. Get an API key from: https://platform.openai.com/api-keys\n",
      "2. Set environment variable: export OPENAI_API_KEY='your-key-here'\n",
      "3. Pass the key directly to setup_environment(openai_key='your-key')\n",
      "\n",
      "ðŸ”§ Troubleshooting Steps:\n",
      "1. Make sure you have a valid OpenAI API key\n",
      "2. Check your internet connection\n",
      "3. Verify all required packages are installed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n!pip install -q langgraph langsmith langchain-openai python-dotenv\\n!pip install -q matplotlib graphviz\\n!pip install langgraph-checkpoint-sqlite\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "LangGraph Chatbot Tutorial - Refactored Version\n",
    "==================================================\n",
    "\n",
    "A comprehensive implementation of a conversational AI chatbot using LangGraph\n",
    "with proper organization, error handling, and testing capabilities.\n",
    "\n",
    "Author: Refactored from original tutorial\n",
    "Date: 2025-06-29\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Third-party imports\n",
    "try:\n",
    "    from langgraph.graph import StateGraph, START, END\n",
    "    from langgraph.graph.message import add_messages\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    "    from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "    from langchain_openai import ChatOpenAI\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Required packages not installed: {e}\")\n",
    "\n",
    "\n",
    "# Configuration and Constants\n",
    "@dataclass\n",
    "class ChatbotConfig:\n",
    "    \"\"\"Configuration settings for the chatbot.\"\"\"\n",
    "    model_name: str = \"gpt-4o-mini\"\n",
    "    temperature: float = 0.7\n",
    "    max_retries: int = 3\n",
    "    timeout: int = 30\n",
    "    \n",
    "    \n",
    "class ConversationState(TypedDict):\n",
    "    \"\"\"Type definition for conversation state.\"\"\"\n",
    "    messages: List[BaseMessage]\n",
    "\n",
    "\n",
    "# Logging setup\n",
    "def setup_logging(level: int = logging.INFO) -> logging.Logger:\n",
    "    \"\"\"Configure logging for the application.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=level,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "logger = setup_logging()\n",
    "\n",
    "\n",
    "class EnvironmentManager:\n",
    "    \"\"\"Manages environment setup and API key configuration.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup_openai_key(api_key: str = None) -> bool:\n",
    "        \"\"\"\n",
    "        Setup OpenAI API key.\n",
    "        \n",
    "        Args:\n",
    "            api_key: Optional API key to use directly (for programmatic setup)\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if already set\n",
    "            existing_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "            if existing_key and existing_key.strip():\n",
    "                logger.info(\"âœ… OpenAI API key already configured\")\n",
    "                return True\n",
    "            \n",
    "            # Use provided key if available\n",
    "            if api_key and api_key.strip():\n",
    "                os.environ[\"OPENAI_API_KEY\"] = api_key.strip()\n",
    "                logger.info(\"âœ… OpenAI API key configured programmatically\")\n",
    "                return True\n",
    "            \n",
    "            # Interactive setup\n",
    "            try:\n",
    "                import getpass\n",
    "                print(\"\\nðŸ”‘ OpenAI API Key Setup\")\n",
    "                print(\"Get your API key from: https://platform.openai.com/api-keys\")\n",
    "                openai_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "                \n",
    "                if not openai_key or not openai_key.strip():\n",
    "                    logger.warning(\"âŒ No OpenAI API key provided\")\n",
    "                    print(\"ðŸ’¡ Tip: You can also set the OPENAI_API_KEY environment variable\")\n",
    "                    return False\n",
    "                \n",
    "                # Validate key format (basic check)\n",
    "                if not openai_key.strip().startswith('sk-'):\n",
    "                    logger.warning(\"âš ï¸ API key doesn't look correct (should start with 'sk-')\")\n",
    "                    confirm = input(\"Continue anyway? (y/N): \")\n",
    "                    if confirm.lower() != 'y':\n",
    "                        return False\n",
    "                \n",
    "                os.environ[\"OPENAI_API_KEY\"] = openai_key.strip()\n",
    "                logger.info(\"âœ… OpenAI API key configured\")\n",
    "                return True\n",
    "                \n",
    "            except ImportError:\n",
    "                logger.error(\"âŒ getpass module not available\")\n",
    "                print(\"Please set OPENAI_API_KEY environment variable manually\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to setup OpenAI key: {e}\")\n",
    "            return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup_langsmith_key(api_key: str = None) -> bool:\n",
    "        \"\"\"\n",
    "        Setup LangSmith API key (optional).\n",
    "        \n",
    "        Args:\n",
    "            api_key: Optional API key to use directly\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if already set\n",
    "            existing_key = os.environ.get(\"LANGSMITH_API_KEY\")\n",
    "            if existing_key and existing_key.strip():\n",
    "                logger.info(\"âœ… LangSmith already configured\")\n",
    "                return True\n",
    "            \n",
    "            # Use provided key if available\n",
    "            if api_key and api_key.strip():\n",
    "                os.environ[\"LANGSMITH_API_KEY\"] = api_key.strip()\n",
    "                os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "                os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph-Tutorial\"\n",
    "                logger.info(\"âœ… LangSmith configured programmatically\")\n",
    "                return True\n",
    "            \n",
    "            # Interactive setup\n",
    "            try:\n",
    "                import getpass\n",
    "                print(\"\\nðŸ“Š LangSmith Setup (Optional - for debugging and monitoring)\")\n",
    "                print(\"Get your API key from: https://smith.langchain.com/\")\n",
    "                langsmith_key = getpass.getpass(\n",
    "                    \"Enter your LangSmith API Key (or press Enter to skip): \"\n",
    "                )\n",
    "                \n",
    "                if langsmith_key and langsmith_key.strip():\n",
    "                    os.environ[\"LANGSMITH_API_KEY\"] = langsmith_key.strip()\n",
    "                    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "                    os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph-Tutorial\"\n",
    "                    logger.info(\"âœ… LangSmith tracing enabled\")\n",
    "                    return True\n",
    "                else:\n",
    "                    logger.info(\"âš ï¸ Skipping LangSmith setup\")\n",
    "                    return False\n",
    "                    \n",
    "            except ImportError:\n",
    "                logger.warning(\"getpass not available for LangSmith setup\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to setup LangSmith: {e}\")\n",
    "            return False\n",
    "    \n",
    "    @classmethod\n",
    "    def setup_environment(cls, openai_key: str = None, langsmith_key: str = None) -> bool:\n",
    "        \"\"\"\n",
    "        Setup complete environment.\n",
    "        \n",
    "        Args:\n",
    "            openai_key: Optional OpenAI API key\n",
    "            langsmith_key: Optional LangSmith API key\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"ðŸš€ Setting up environment...\")\n",
    "            \n",
    "            # Setup OpenAI (required)\n",
    "            openai_success = cls.setup_openai_key(openai_key)\n",
    "            if not openai_success:\n",
    "                logger.error(\"âŒ Environment setup failed - OpenAI key required\")\n",
    "                print(\"\\nðŸ’¡ Solutions:\")\n",
    "                print(\"1. Get an API key from: https://platform.openai.com/api-keys\")\n",
    "                print(\"2. Set environment variable: export OPENAI_API_KEY='your-key-here'\")\n",
    "                print(\"3. Pass the key directly to setup_environment(openai_key='your-key')\")\n",
    "                return False\n",
    "            \n",
    "            # Setup LangSmith (optional)\n",
    "            cls.setup_langsmith_key(langsmith_key)\n",
    "            \n",
    "            logger.info(\"ðŸš€ Environment setup complete\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Environment setup failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_environment() -> bool:\n",
    "        \"\"\"Validate that required environment variables are set.\"\"\"\n",
    "        required_vars = [\"OPENAI_API_KEY\"]\n",
    "        missing_vars = []\n",
    "        \n",
    "        for var in required_vars:\n",
    "            if not os.environ.get(var):\n",
    "                missing_vars.append(var)\n",
    "        \n",
    "        if missing_vars:\n",
    "            logger.error(f\"Missing required environment variables: {missing_vars}\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "\n",
    "class LLMManager:\n",
    "    \"\"\"Manages the Language Model instance and operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ChatbotConfig):\n",
    "        self.config = config\n",
    "        self._llm = None\n",
    "    \n",
    "    @property\n",
    "    def llm(self) -> ChatOpenAI:\n",
    "        \"\"\"Lazy initialization of the LLM.\"\"\"\n",
    "        if self._llm is None:\n",
    "            self._llm = self._create_llm()\n",
    "        return self._llm\n",
    "    \n",
    "    def _create_llm(self) -> ChatOpenAI:\n",
    "        \"\"\"Create and configure the language model.\"\"\"\n",
    "        try:\n",
    "            llm = ChatOpenAI(\n",
    "                model=self.config.model_name,\n",
    "                temperature=self.config.temperature,\n",
    "                max_retries=self.config.max_retries,\n",
    "                request_timeout=self.config.timeout,\n",
    "            )\n",
    "            logger.info(f\"âœ… Language model initialized: {self.config.model_name}\")\n",
    "            return llm\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize LLM: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def test_connection(self) -> bool:\n",
    "        \"\"\"Test the LLM connection.\"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(\"Say hello in a friendly way!\")\n",
    "            logger.info(f\"âœ… LLM test successful: {response.content[:50]}...\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM test failed: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "class ChatbotNode:\n",
    "    \"\"\"Encapsulates the chatbot node functionality.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_manager: LLMManager):\n",
    "        self.llm_manager = llm_manager\n",
    "    \n",
    "    def process(self, state: ConversationState) -> Dict[str, List[BaseMessage]]:\n",
    "        \"\"\"\n",
    "        Process the conversation state and generate a response.\n",
    "        \n",
    "        Args:\n",
    "            state: Current conversation state containing message history\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing new messages to add to state\n",
    "            \n",
    "        Raises:\n",
    "            Exception: If LLM processing fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            messages = state[\"messages\"]\n",
    "            if not messages:\n",
    "                raise ValueError(\"No messages in state\")\n",
    "            \n",
    "            response = self.llm_manager.llm.invoke(messages)\n",
    "            \n",
    "            if not response or not response.content:\n",
    "                raise ValueError(\"Empty response from LLM\")\n",
    "            \n",
    "            return {\"messages\": [response]}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Chatbot node processing failed: {e}\")\n",
    "            # Return an error message instead of crashing\n",
    "            error_response = AIMessage(\n",
    "                content=\"I apologize, but I encountered an error processing your request. Please try again.\"\n",
    "            )\n",
    "            return {\"messages\": [error_response]}\n",
    "\n",
    "\n",
    "class ConversationManager:\n",
    "    \"\"\"Manages conversation threads and memory.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memory = MemorySaver()\n",
    "        self._active_threads: Dict[str, Any] = {}\n",
    "    \n",
    "    def create_thread_id(self) -> str:\n",
    "        \"\"\"Generate a unique thread ID.\"\"\"\n",
    "        return str(uuid.uuid4())\n",
    "    \n",
    "    def get_config(self, thread_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get configuration for a conversation thread.\"\"\"\n",
    "        return {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    def list_active_threads(self) -> List[str]:\n",
    "        \"\"\"List all active conversation threads.\"\"\"\n",
    "        return list(self._active_threads.keys())\n",
    "\n",
    "\n",
    "class LangGraphChatbot:\n",
    "    \"\"\"Main chatbot class that orchestrates all components.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Optional[ChatbotConfig] = None):\n",
    "        self.config = config or ChatbotConfig()\n",
    "        self.llm_manager = LLMManager(self.config)\n",
    "        self.conversation_manager = ConversationManager()\n",
    "        self.chatbot_node = ChatbotNode(self.llm_manager)\n",
    "        \n",
    "        # Build graphs\n",
    "        self._simple_graph = None\n",
    "        self._memory_graph = None\n",
    "    \n",
    "    def _build_simple_graph(self):\n",
    "        \"\"\"Build the simple chatbot graph without memory.\"\"\"\n",
    "        try:\n",
    "            graph_builder = StateGraph(ConversationState)\n",
    "            graph_builder.add_node(\"chatbot\", self.chatbot_node.process)\n",
    "            graph_builder.add_edge(START, \"chatbot\")\n",
    "            graph_builder.add_edge(\"chatbot\", END)\n",
    "            \n",
    "            self._simple_graph = graph_builder.compile()\n",
    "            logger.info(\"âœ… Simple chatbot graph created\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to build simple graph: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _build_memory_graph(self):\n",
    "        \"\"\"Build the chatbot graph with memory.\"\"\"\n",
    "        try:\n",
    "            graph_builder = StateGraph(ConversationState)\n",
    "            graph_builder.add_node(\"chatbot\", self.chatbot_node.process)\n",
    "            graph_builder.add_edge(START, \"chatbot\")\n",
    "            graph_builder.add_edge(\"chatbot\", END)\n",
    "            \n",
    "            self._memory_graph = graph_builder.compile(\n",
    "                checkpointer=self.conversation_manager.memory\n",
    "            )\n",
    "            logger.info(\"âœ… Memory-enabled chatbot graph created\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to build memory graph: {e}\")\n",
    "            raise\n",
    "    \n",
    "    @property\n",
    "    def simple_graph(self):\n",
    "        \"\"\"Get the simple graph (lazy initialization).\"\"\"\n",
    "        if self._simple_graph is None:\n",
    "            self._build_simple_graph()\n",
    "        return self._simple_graph\n",
    "    \n",
    "    @property\n",
    "    def memory_graph(self):\n",
    "        \"\"\"Get the memory-enabled graph (lazy initialization).\"\"\"\n",
    "        if self._memory_graph is None:\n",
    "            self._build_memory_graph()\n",
    "        return self._memory_graph\n",
    "    \n",
    "    def chat_simple(self, user_input: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Simple chat without memory.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's message\n",
    "            \n",
    "        Returns:\n",
    "            Conversation result\n",
    "        \"\"\"\n",
    "        try:\n",
    "            initial_state = {\n",
    "                \"messages\": [HumanMessage(content=user_input)]\n",
    "            }\n",
    "            return self.simple_graph.invoke(initial_state)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Simple chat failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def chat_with_memory(self, user_input: str, thread_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Chat with memory persistence.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's message\n",
    "            thread_id: Optional thread ID (creates new if None)\n",
    "            \n",
    "        Returns:\n",
    "            Conversation result\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if thread_id is None:\n",
    "                thread_id = self.conversation_manager.create_thread_id()\n",
    "            \n",
    "            config = self.conversation_manager.get_config(thread_id)\n",
    "            \n",
    "            result = self.memory_graph.invoke(\n",
    "                {\"messages\": [HumanMessage(content=user_input)]},\n",
    "                config\n",
    "            )\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Memory chat failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def initialize(self) -> bool:\n",
    "        \"\"\"Initialize the chatbot system.\"\"\"\n",
    "        try:\n",
    "            # Setup environment\n",
    "            if not EnvironmentManager.setup_environment():\n",
    "                return False\n",
    "            \n",
    "            # Test LLM connection\n",
    "            if not self.llm_manager.test_connection():\n",
    "                return False\n",
    "            \n",
    "            # Build graphs (lazy initialization will happen on first use)\n",
    "            logger.info(\"ðŸŽ‰ Chatbot system initialized successfully\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Initialization failed: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "class ChatbotTester:\n",
    "    \"\"\"Testing utilities for the chatbot system.\"\"\"\n",
    "    \n",
    "    def __init__(self, chatbot: LangGraphChatbot):\n",
    "        self.chatbot = chatbot\n",
    "    \n",
    "    def print_conversation(self, result: Dict[str, Any], title: str = \"\"):\n",
    "        \"\"\"Pretty print conversation results.\"\"\"\n",
    "        if title:\n",
    "            print(f\"\\nðŸ¤– {title}\")\n",
    "            print(\"=\" * (len(title) + 4))\n",
    "        \n",
    "        messages = result.get(\"messages\", [])\n",
    "        for message in messages:\n",
    "            if isinstance(message, HumanMessage):\n",
    "                print(f\"ðŸ‘¤ Human: {message.content}\")\n",
    "            elif isinstance(message, AIMessage):\n",
    "                print(f\"ðŸ¤– AI: {message.content}\")\n",
    "        print()\n",
    "    \n",
    "    def test_simple_chatbot(self, test_cases: List[str]):\n",
    "        \"\"\"Test simple chatbot functionality.\"\"\"\n",
    "        print(\"ðŸ§ª Testing Simple Chatbot\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        for i, test_case in enumerate(test_cases, 1):\n",
    "            try:\n",
    "                result = self.chatbot.chat_simple(test_case)\n",
    "                self.print_conversation(result, f\"Test Case {i}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Test case {i} failed: {e}\")\n",
    "    \n",
    "    def test_memory_functionality(self, thread_id: str = \"test_conversation\"):\n",
    "        \"\"\"Test memory functionality.\"\"\"\n",
    "        print(\"ðŸ§  Testing Memory Functionality\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        test_sequence = [\n",
    "            \"Hi! My name is Niyantarana Tagore and I am an AI Agent Developer.\",\n",
    "            \"What's my name and what do I do?\",\n",
    "            \"What programming languages should I learn for AI development?\"\n",
    "        ]\n",
    "        \n",
    "        for i, user_input in enumerate(test_sequence, 1):\n",
    "            try:\n",
    "                result = self.chatbot.chat_with_memory(user_input, thread_id)\n",
    "                self.print_conversation(result, f\"Memory Test {i}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Memory test {i} failed: {e}\")\n",
    "    \n",
    "    def test_thread_isolation(self):\n",
    "        \"\"\"Test that different threads maintain separate conversations.\"\"\"\n",
    "        print(\"ðŸ”„ Testing Thread Isolation\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # First conversation\n",
    "        result1 = self.chatbot.chat_with_memory(\n",
    "            \"My favorite color is blue\", \n",
    "            \"thread_1\"\n",
    "        )\n",
    "        self.print_conversation(result1, \"Thread 1 - Setup\")\n",
    "        \n",
    "        # Second conversation\n",
    "        result2 = self.chatbot.chat_with_memory(\n",
    "            \"My favorite color is red\", \n",
    "            \"thread_2\"\n",
    "        )\n",
    "        self.print_conversation(result2, \"Thread 2 - Setup\")\n",
    "        \n",
    "        # Test memory isolation\n",
    "        result3 = self.chatbot.chat_with_memory(\n",
    "            \"What's my favorite color?\", \n",
    "            \"thread_1\"\n",
    "        )\n",
    "        self.print_conversation(result3, \"Thread 1 - Recall\")\n",
    "        \n",
    "        result4 = self.chatbot.chat_with_memory(\n",
    "            \"What's my favorite color?\", \n",
    "            \"thread_2\"\n",
    "        )\n",
    "        self.print_conversation(result4, \"Thread 2 - Recall\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function demonstrating the chatbot usage.\"\"\"\n",
    "    print(\"ðŸ¤– LangGraph Chatbot System\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Initialize chatbot\n",
    "    config = ChatbotConfig(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    chatbot = LangGraphChatbot(config)\n",
    "    \n",
    "    # Initialize system\n",
    "    if not chatbot.initialize():\n",
    "        logger.error(\"Failed to initialize chatbot system\")\n",
    "        print(\"\\nðŸ”§ Troubleshooting Steps:\")\n",
    "        print(\"1. Make sure you have a valid OpenAI API key\")\n",
    "        print(\"2. Check your internet connection\")\n",
    "        print(\"3. Verify all required packages are installed\")\n",
    "        return\n",
    "    \n",
    "    # Run tests\n",
    "    tester = ChatbotTester(chatbot)\n",
    "    \n",
    "    try:\n",
    "        # Test simple functionality\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        simple_test_cases = [\n",
    "            \"Hello! What's your name?\",\n",
    "            \"What is the GATE cutoff for ECE?\",\n",
    "            \"What are the subjects in GATE ECE?\"\n",
    "        ]\n",
    "        tester.test_simple_chatbot(simple_test_cases)\n",
    "        \n",
    "        # Test memory functionality\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        tester.test_memory_functionality()\n",
    "        \n",
    "        # Test thread isolation\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        tester.test_thread_isolation()\n",
    "        \n",
    "        print(\"âœ… All tests completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Testing failed: {e}\")\n",
    "        print(\"âŒ Some tests failed. Check the logs above for details.\")\n",
    "\n",
    "\n",
    "# Convenience function for easy setup\n",
    "def quick_setup(openai_key: str = None):\n",
    "    \"\"\"\n",
    "    Quick setup function for easy initialization.\n",
    "    \n",
    "    Args:\n",
    "        openai_key: Your OpenAI API key\n",
    "        \n",
    "    Returns:\n",
    "        LangGraphChatbot: Initialized chatbot instance\n",
    "    \"\"\"\n",
    "    # Setup environment\n",
    "    if not EnvironmentManager.setup_environment(openai_key=openai_key):\n",
    "        return None\n",
    "    \n",
    "    # Create and initialize chatbot\n",
    "    config = ChatbotConfig()\n",
    "    chatbot = LangGraphChatbot(config)\n",
    "    \n",
    "    if chatbot.initialize():\n",
    "        print(\"âœ… Chatbot ready to use!\")\n",
    "        return chatbot\n",
    "    else:\n",
    "        print(\"âŒ Failed to initialize chatbot\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage functions\n",
    "def example_simple_chat():\n",
    "    \"\"\"Example of simple chat usage.\"\"\"\n",
    "    chatbot = quick_setup()\n",
    "    if not chatbot:\n",
    "        return\n",
    "    \n",
    "    # Simple chat examples\n",
    "    test_messages = [\n",
    "        \"Hello, how are you?\",\n",
    "        \"What can you help me with?\",\n",
    "        \"Tell me a joke\"\n",
    "    ]\n",
    "    \n",
    "    for msg in test_messages:\n",
    "        print(f\"\\nðŸ‘¤ User: {msg}\")\n",
    "        try:\n",
    "            result = chatbot.chat_simple(msg)\n",
    "            ai_response = result[\"messages\"][-1].content\n",
    "            print(f\"ðŸ¤– AI: {ai_response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "\n",
    "\n",
    "def example_memory_chat():\n",
    "    \"\"\"Example of memory-enabled chat.\"\"\"\n",
    "    chatbot = quick_setup()\n",
    "    if not chatbot:\n",
    "        return\n",
    "    \n",
    "    thread_id = \"example_conversation\"\n",
    "    \n",
    "    # Conversation with memory\n",
    "    conversation = [\n",
    "        \"Hi, my name is Alice and I'm a software engineer.\",\n",
    "        \"What's my name?\",\n",
    "        \"What do I do for work?\",\n",
    "        \"Can you remember what we talked about?\"\n",
    "    ]\n",
    "    \n",
    "    for msg in conversation:\n",
    "        print(f\"\\nðŸ‘¤ User: {msg}\")\n",
    "        try:\n",
    "            result = chatbot.chat_with_memory(msg, thread_id)\n",
    "            ai_response = result[\"messages\"][-1].content\n",
    "            print(f\"ðŸ¤– AI: {ai_response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# Installation requirements (run these in separate cells in Jupyter)\n",
    "\"\"\"\n",
    "!pip install -q langgraph langsmith langchain-openai python-dotenv\n",
    "!pip install -q matplotlib graphviz\n",
    "!pip install langgraph-checkpoint-sqlite\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151c813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8948c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bia_genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
